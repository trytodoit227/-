# -百度飞桨-图神经网络7日学习课程
通过课程的学习，学到了很多经典图模型，同时针对自己薄弱的代码环节，课程也有针对性的实战。通过对模型原理和代码的学习，加深对算法的理解和认知。以下是课程主要内容的回顾：
一。图游走模型概述
  图游走的目标：
      学习出图中每一个节点的低维表示，称为 Node Embeddings。得到节点的低维表示后，可以利用这些低维表示来进行接下来的下游任务，比如节点分类等。

  图游走的步骤：
      通过在图进行某种方式的游走，得到多个序列，利用这些序列进行图表示学习
      通过图表示学习，利用节点之间的关系，学习到节点的低维表示(Node Embedding)
      利用这些Embeddings做下游任务
 二。GCN。GAT以及消息传递
    Graph Attention Network (GAT) 引入了注意力机制来实现更好的邻居聚合。通过学习邻居的权重，GAT 可以实现对邻居的加权聚合。因此，GAT 不仅对于噪音邻居较为鲁棒，
 注意力机制也赋予了模型一定的可解释性。
 三。图采样和邻居聚合
     （1）GraphSAGE则是一种能够利用顶点的属性信息高效产生未知顶点embedding的一种归纳式(inductive)学习的框架。
其核心思想是通过学习一个对邻居顶点进行聚合表示的函数来产生目标顶点的embedding向量。GraphSAGE算法原理可表示如下：
    GraphSAGE 是Graph SAmple and aggreGatE的缩写，其实现过程可以分为三个步骤
       对图中每个顶点邻居顶点进行采样
       根据聚合函数从聚合邻居顶点蕴含的信息
       得到图中各顶点的向量表示供下游任务
     （2）聚合函数的选取
由于在图中顶点的邻居是天然无序的，所以我们希望构造出的聚合函数是对称的（即改变输入的顺序，函数的输出结果不变），同时具有较高的表达能力。
聚合的方法一般有：MEAN aggregator，Pooling aggregator，LSTM aggregator等。
四。ERNIESage和UniMP模型
   ERNIESage可以很轻松地在PGL中的消息传递范式中进行实现，目前PGL提供了3个版本的ERNIESage模型：
      ERNIESage v1: ERNIE 作用于text graph节点上;
      ERNIESage v2: ERNIE 作用在text graph的边上;
      ERNIESage v3: ERNIE 作用于一阶邻居及起边
   UniMP模型：在半监督图节点分类场景下，节点之间通过边相连接，部分节点被打上标签。任务要求模型通过监督学习的方式，拟合被标注节点数据，并对未标注的节点进行预测。
在一般机器学习的问题上，已标注的训练数据在新数据的推断上，并不能发挥直接的作用，因为数据的输入是独立的。然而在图神经网络的场景下，
已有的标注数据可以从节点与节点的连接中，根据图结构关系推广到新的未标注数据中
墙裂推荐该课程哟！对于入门图神经网络是很不错的呢，奉上课程链接：https://aistudio.baidu.com/aistudio/education/group/info/1956
